# DRL TurboEngine

A Deep Reinforcement Learning (DRL) engine designed to train agents on high-speed navigation tasks using custom track environments. This repository includes the full training pipeline, race environment, deployment scripts, and visualization assets.

---

## ğŸš€ Project Overview
DRL TurboEngine is an endâ€‘toâ€‘end framework built for training autonomous agents in racing-style environments. It includes:

- **Custom Race Environment** built using Python
- **Agent Training Pipeline** with reward functions, environment loops, and episode management
- **Deployment Module** to run trained policies in real-time
- **Track Assets** in both **STL** and **XML** formats
- **Testing Scripts** for validating performance

The goal of this project is to experiment with DRL in custom navigation tasks â€” such as racing, obstacle avoidance, and trajectory optimization.

---

## ğŸ“‚ Repository Structure
```
DRL_TurboEngine/
â”‚
â”œâ”€â”€ TurboCore.py                # Core utilities and shared functions
â”œâ”€â”€ TurboTraining.py            # DRL training loop
â”œâ”€â”€ TurboDeploy.py              # Deployment / inference script
â”œâ”€â”€ TurboRaceEnvironment.py     # Custom racing environment
â”œâ”€â”€ EnvironmentTeasting.py      # Environment testing script
â”‚
â”œâ”€â”€ Tracks_STL/                 # Track models (STL format)
â”‚   â””â”€â”€ Track_V1/
â”‚
â”œâ”€â”€ Tracks_XML/                 # Track definitions (XML based)
â”‚
â”œâ”€â”€ assets/                     # Images and videos
â”‚   â”œâ”€â”€ rover_image.png         # Rover model image
â”‚   â””â”€â”€ rover_track_demo.mp4    # Demo video of rover navigating track
â”‚
â””â”€â”€ README.md                   # Documentation (this file)
```

---

## ğŸ§  How It Works
### 1. **Environment**
The `TurboRaceEnvironment` simulates a racing-style track system. It provides:
- Observations
- Rewards
- Actions
- Episode logic

You can modify the track design, boundaries, and rules.

### 2. **Training**
`TurboTraining.py` handles:
- Agent initialization
- Episode loops
- Reward computation
- Logging & saving checkpoints

### 3. **Deployment**
`TurboDeploy.py` loads the trained model and runs it over the track for visualization or benchmarking.

---

## ğŸ“¸ Demo Assets
### ğŸ–¼ Rover Image
An image showcasing the rover used during training.
```
assets/rover_image.png
```

### ğŸ¥ Navigation Demo Video
A video of the rover navigating through the track.
```
assets/rover_track_demo.mp4
```

---

## â–¶ï¸ Getting Started
### **Clone the repository**
```
git clone https://github.com/Karthibs/DRL_TurboEngine.git
cd DRL_TurboEngine
```

### **Run Environment Test**
```
python EnvironmentTeasting.py
```

### **Start Training**
```
python TurboTraining.py
```

### **Run Deployment / Demo**
```
python TurboDeploy.py
```

---

## ğŸ›  Requirements
- Python 3.9+
- NumPy
- OpenCV (for video)
- PyTorch / TensorFlow (depending on your implementation)
- Matplotlib (optional for visualization)

Install dependencies:
```
pip install -r requirements.txt
```

---

## ğŸ“Œ Future Improvements
- Add PPO/SAC implementations
- Add more complex tracks
- Add LiDARâ€‘based or cameraâ€‘based observations
- Evaluate simâ€‘toâ€‘real performance

---

## ğŸ“§ Contact
Created by **Karthikeya Reddy**

If you use this repository or want to collaborate, feel free to reach out!

